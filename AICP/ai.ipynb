{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exception with error code: \n[CALL STACK BEGIN]\n\n    > pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - recognizer_create_speech_recognizer_from_config\n    - recognizer_create_speech_recognizer_from_config\n\n[CALL STACK END]\n\nException with an error code: 0xa (SPXERR_INVALID_HEADER)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mChuHongHeMike\\schulich_data_science_he55\\AICP\\ai.ipynb Cell 1\u001b[0m line \u001b[0;36m<cell line: 38>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://github/ChuHongHeMike/schulich_data_science_he55/AICP/ai.ipynb#W0sdnNjb2RlLXZmcw%3D%3D?line=34'>35</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError details: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(cancellation_details\u001b[39m.\u001b[39merror_details))\n\u001b[0;32m     <a href='vscode-notebook-cell://github/ChuHongHeMike/schulich_data_science_he55/AICP/ai.ipynb#W0sdnNjb2RlLXZmcw%3D%3D?line=36'>37</a>\u001b[0m audio_filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mC:/Users/hechu/Downloads/1st_Meeting_4th_Session_Open-ended_Working_Group_on_Reducing_Space_Threats-Kaltura-1_vyc9qx1u-hls-audio-English.mp4\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell://github/ChuHongHeMike/schulich_data_science_he55/AICP/ai.ipynb#W0sdnNjb2RlLXZmcw%3D%3D?line=37'>38</a>\u001b[0m recognize_from_audio_file(audio_filename)\n",
      "\u001b[1;32mChuHongHeMike\\schulich_data_science_he55\\AICP\\ai.ipynb Cell 1\u001b[0m line \u001b[0;36mrecognize_from_audio_file\u001b[1;34m(audio_filename)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://github/ChuHongHeMike/schulich_data_science_he55/AICP/ai.ipynb#W0sdnNjb2RlLXZmcw%3D%3D?line=17'>18</a>\u001b[0m audio_config \u001b[39m=\u001b[39m speechsdk\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39mAudioConfig(filename\u001b[39m=\u001b[39maudio_filename)\n\u001b[0;32m     <a href='vscode-notebook-cell://github/ChuHongHeMike/schulich_data_science_he55/AICP/ai.ipynb#W0sdnNjb2RlLXZmcw%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell://github/ChuHongHeMike/schulich_data_science_he55/AICP/ai.ipynb#W0sdnNjb2RlLXZmcw%3D%3D?line=20'>21</a>\u001b[0m speech_recognizer \u001b[39m=\u001b[39m speechsdk\u001b[39m.\u001b[39;49mSpeechRecognizer(speech_config\u001b[39m=\u001b[39;49mspeech_config, audio_config\u001b[39m=\u001b[39;49maudio_config)\n\u001b[0;32m     <a href='vscode-notebook-cell://github/ChuHongHeMike/schulich_data_science_he55/AICP/ai.ipynb#W0sdnNjb2RlLXZmcw%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRecognizing speech from audio file: \u001b[39m\u001b[39m{\u001b[39;00maudio_filename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell://github/ChuHongHeMike/schulich_data_science_he55/AICP/ai.ipynb#W0sdnNjb2RlLXZmcw%3D%3D?line=23'>24</a>\u001b[0m speech_recognition_result \u001b[39m=\u001b[39m speech_recognizer\u001b[39m.\u001b[39mrecognize_once_async()\u001b[39m.\u001b[39mget()\n",
      "File \u001b[1;32mc:\\Users\\hechu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\cognitiveservices\\speech\\speech.py:1006\u001b[0m, in \u001b[0;36mSpeechRecognizer.__init__\u001b[1;34m(self, speech_config, audio_config, language, source_language_config, auto_detect_source_language_config)\u001b[0m\n\u001b[0;32m   1004\u001b[0m audio_config_handle \u001b[39m=\u001b[39m audio_config\u001b[39m.\u001b[39m_handle \u001b[39mif\u001b[39;00m audio_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[39mif\u001b[39;00m language \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m source_language_config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m auto_detect_source_language_config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1006\u001b[0m     _call_hr_fn(\n\u001b[0;32m   1007\u001b[0m         fn\u001b[39m=\u001b[39;49m_sdk_lib\u001b[39m.\u001b[39;49mrecognizer_create_speech_recognizer_from_config,\n\u001b[0;32m   1008\u001b[0m         \u001b[39m*\u001b[39;49m[ctypes\u001b[39m.\u001b[39;49mbyref(handle), speech_config\u001b[39m.\u001b[39;49m_handle, audio_config_handle])\n\u001b[0;32m   1009\u001b[0m \u001b[39melif\u001b[39;00m language \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1010\u001b[0m     source_language_config \u001b[39m=\u001b[39m languageconfig\u001b[39m.\u001b[39mSourceLanguageConfig(language)\n",
      "File \u001b[1;32mc:\\Users\\hechu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\cognitiveservices\\speech\\interop.py:62\u001b[0m, in \u001b[0;36m_call_hr_fn\u001b[1;34m(fn, *args)\u001b[0m\n\u001b[0;32m     60\u001b[0m fn\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m _spx_hr\n\u001b[0;32m     61\u001b[0m hr \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m fn()\n\u001b[1;32m---> 62\u001b[0m _raise_if_failed(hr)\n",
      "File \u001b[1;32mc:\\Users\\hechu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\cognitiveservices\\speech\\interop.py:55\u001b[0m, in \u001b[0;36m_raise_if_failed\u001b[1;34m(hr)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_if_failed\u001b[39m(hr: _spx_hr):\n\u001b[0;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m hr \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 55\u001b[0m         __try_get_error(_spx_handle(hr))\n\u001b[0;32m     56\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(hr)\n",
      "File \u001b[1;32mc:\\Users\\hechu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azure\\cognitiveservices\\speech\\interop.py:50\u001b[0m, in \u001b[0;36m__try_get_error\u001b[1;34m(error_handle)\u001b[0m\n\u001b[0;32m     45\u001b[0m message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mException with error code: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[0;32m     46\u001b[0m     callstack \u001b[39mif\u001b[39;00m callstack \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     what \u001b[39mif\u001b[39;00m what \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m code\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     49\u001b[0m _sdk_lib\u001b[39m.\u001b[39merror_release(error_handle)\n\u001b[1;32m---> 50\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(message)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exception with error code: \n[CALL STACK BEGIN]\n\n    > pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - pal_string_to_wstring\n    - recognizer_create_speech_recognizer_from_config\n    - recognizer_create_speech_recognizer_from_config\n\n[CALL STACK END]\n\nException with an error code: 0xa (SPXERR_INVALID_HEADER)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ['SPEECH_KEY'] = 'ef888ca2899e4e40844b94ca568e5bff'\n",
    "os.environ['SPEECH_REGION'] = 'northcentralus'\n",
    "\n",
    "def recognize_from_audio_file(audio_filename):\n",
    "    # \n",
    "    speech_key = os.environ.get('SPEECH_KEY')\n",
    "    speech_region = os.environ.get('SPEECH_REGION')\n",
    "\n",
    "    # \n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    speech_config.speech_recognition_language=\"en-US\"\n",
    "\n",
    "    # \n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=audio_filename)\n",
    "\n",
    "    # \n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    print(f\"Recognizing speech from audio file: {audio_filename}\")\n",
    "    speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "\n",
    "    # \n",
    "    if speech_recognition_result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"Recognized: {}\".format(speech_recognition_result.text))\n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.NoMatch:\n",
    "        print(\"No speech could be recognized.\")\n",
    "    elif speech_recognition_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_recognition_result.cancellation_details\n",
    "        print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n",
    "audio_filename = 'C:/Users/hechu/Downloads/1st_Meeting_4th_Session_Open-ended_Working_Group_on_Reducing_Space_Threats-Kaltura-1_vyc9qx1u-hls-audio-English.mp4'\n",
    "recognize_from_audio_file(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import Gst\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time\n",
    "\n",
    "# 初始化 GStreamer\n",
    "Gst.init(None)\n",
    "\n",
    "class GStreamerAudioStream(speechsdk.audio.PullAudioInputStreamCallback):\n",
    "    def __init__(self, mp4_filename):\n",
    "        super().__init__()\n",
    "        self.pipeline = Gst.parse_launch(f'filesrc location=\"{mp4_filename}\" ! decodebin ! audioconvert ! audioresample ! appsink name=sink sync=true')\n",
    "        self.appsink = self.pipeline.get_by_name('sink')\n",
    "        self.pipeline.set_state(Gst.State.PLAYING)\n",
    "\n",
    "    def read(self, buffer):\n",
    "        sample = self.appsink.emit('pull-sample')\n",
    "        if sample:\n",
    "            buf = sample.get_buffer()\n",
    "            data = buf.extract_dup(0, buf.get_size())\n",
    "            buffer[:len(data)] = data\n",
    "            return len(data)\n",
    "        return 0\n",
    "\n",
    "    def close(self):\n",
    "        self.pipeline.set_state(Gst.State.NULL)\n",
    "\n",
    "def recognize_from_mp4(mp4_filename):\n",
    "    speech_key = \"your_speech_key\"\n",
    "    speech_region = \"your_speech_region\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region)\n",
    "    \n",
    "    stream = GStreamerAudioStream(mp4_filename)\n",
    "    audio_config = speechsdk.audio.AudioConfig(stream=stream)\n",
    "    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # 设置识别器的各种事件\n",
    "    recognizer.recognizing.connect(lambda evt: print(f\"RECOGNIZING: {evt.result.text}\"))\n",
    "    recognizer.recognized.connect(lambda evt: print(f\"RECOGNIZED: {evt.result.text}\"))\n",
    "    recognizer.session_started.connect(lambda evt: print(\"SESSION STARTED: {}\".format(evt)))\n",
    "    recognizer.session_stopped.connect(lambda evt: print(\"SESSION STOPPED\"))\n",
    "    recognizer.canceled.connect(lambda evt: print(f\"CANCELED: {evt}\"))\n",
    "\n",
    "    # 开始连续识别\n",
    "    recognizer.start_continuous_recognition()\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        # 停止连续识别\n",
    "        recognizer.stop_continuous_recognition()\n",
    "\n",
    "mp4_filename = 'path_to_your_mp4_file.mp4'\n",
    "recognize_from_mp4(mp4_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
